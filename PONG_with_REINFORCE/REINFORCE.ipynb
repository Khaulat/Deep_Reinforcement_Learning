{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trains an agent to play pong using the REINFORCE algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: JSAnimation in /home/khaulat/anaconda3/lib/python3.7/site-packages (0.1)\r\n"
     ]
    }
   ],
   "source": [
    "# import dependencies\n",
    "\n",
    "import gym\n",
    "import time\n",
    "import pong_utils\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pong_utils\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# for displaying animation\n",
    "!pip install JSAnimation\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of available actions:  ['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']\n"
     ]
    }
   ],
   "source": [
    "# create pong environment\n",
    "\n",
    "env = gym.make('PongDeterministic-v4')\n",
    "print(\"List of available actions: \", env.unwrapped.get_action_meanings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa2aac53190>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD3CAYAAADmBxSSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAdaElEQVR4nO3de7xd853/8de7IVSDIKEkIWgo+qgw56fUoy1Vt1KXPlojQ6WqDVM69ePxa9GZoUXLjEv1oUPjbhDXGhkM0pSaTkklBIkwIqI5RC5CxaVIfH5/rO+plZO9z9nn7L3P2nt5Px+P89hrfdfts9dOPvu7v2ut71cRgZmZlctHig7AzMwaz8ndzKyEnNzNzErIyd3MrISc3M3MSsjJ3cyshJzc6yDpUkn/1Oh1e9nPaEkhaY0qy2dL2qPe45hZe5Pvc28vkkYDzwNrRsSKYqMxs1blmns/SRpUdAxmZtU4uedI2k7SA5JeS80bB+WWXS3pEkl3S3oT2DOVnZVb5weSFkp6SdK3U/PJJ3Lbn5Wm95DUKelkSYvTNkfn9nOApMckvS5pgaQz+vAe5kv6Upo+Q9Itkq6TtFzSk5K2kXRqOu4CSfvktj1a0py07jxJx3bbd0/vby1J50n6k6RFqRnqo339DMysMZzcE0lrAv8J3AdsDHwPuF7StrnV/g44G1gX+H237fcDTgK+BHwC+EIvh/w4sD4wAjgG+KWkDdKyN4GjgKHAAcDfSzqkn2/tK8C/AxsAjwH3kn3uI4CfAL/KrbsYOBBYDzgauFDSzjW+v3OBbYCxafkI4J/7GbOZ1cnJ/QO7AkOAcyLi3Yj4LXAnMC63zh0R8T8R8X5E/KXb9ocBV0XE7Ih4C/hxL8d7D/hJRLwXEXcDbwDbAkTEAxHxZDrOE8Akev+yqOa/I+Le1D5/CzA8vcf3gBuB0ZKGpuPeFRHPReZ3ZF90n+vt/UkS8B3g/0bEsohYDvwUOLyfMZtZnSrecfEhtRmwICLez5W9QFYD7bKgl+2n17guwCvdLoi+RfblgqTPAOcAnwIGA2uRJeb+WJSbfhtYGhErc/Ok474maX/gdLIa+EeAdYAn0zo9vb/had0ZWZ4HQICvS5gVxDX3D7wEjJKUPyebAy/m5nu6tWghMDI3P6qOWG4AJgOjImJ94FKyZNk0ktYCbgPOAzaJiKHA3bnj9vT+lpJ9UewQEUPT3/oRMaSZMZtZdU7uH5hG1tb9A0lrpnvFv0LWdFGLm4Gj00XZdaivvXldYFlE/EXSLmRt/c3W9QthCbAi1eL3yS2v+v7Sr53LyNroNwaQNELSvgMQt5lV4OSeRMS7wEHA/mQ10X8DjoqIp2vc/r+AXwD3A3OBh9Kid/oRzneBn0haTpZEb+7HPvoktZP/QzrWq2RfKJNzy3t7fz9M5Q9Leh34DekagpkNPD/E1CSStgNmAWuV8WGjsr8/s3bnmnsDSTpU0uB0S+O5wH+WKfGV/f2ZlYmTe2MdS9Zm/RywEvj7YsNpuLK/P7PSaFqzTHro5SKy2+Euj4hzmnIgMzNbTVOSe+p35X+BvYFO4BFgXEQ81fCDmZnZaprVLLMLMDci5qW7UG4EDm7SsczMrJtmPaE6glWfYOwEPlNtZUk9/nwYtZ4fdLT6LHh95dKIGF50HGYDpVnJvdLTlKskcEkTgAkAG6z9EU7fY/0mhVK7vT+7W5/Wn/KHh3pfqeSmn3RAzet2XHBXEyPp2Yn3vPpCYQc3K0CzmmU6WfXx9JFkj/f/VURMjIiOiOgYMripT9abmX3oNCu5PwKMkbSlpMFkvQNO7mUbMzNrkKY0y0TECkknkPUdPgi4MiJmN+NYZma2uqZ1+Zv6KL+7WfsfCN3b1PvaJv9h1L1dvS9t8mbWOH5C1cyshJzczcxKyMndzEonDXT/7SrLTpN0+UDHNNA8zJ6ZfahExE+LjmEguOZuVhKSGlpZa/T+bGA5uZu1MEnzJZ0q6SlJr0q6StLaadkekjol/VDSy8BVqfxASTMlvSbpD5I+Xef+viNprqRlkiZL2iy3vx0kTUnLFkk6LZV/RNIpkp6T9IqkmyVtmJatLem6VP6apEckbZKWfVPSPEnLJT0v6Yjcsb4laU6K+15JW+SW7S3paUl/lnQxPYw5LOkMSdel6dGSQtLRkhakfR8n6f9IeiLFd3Fu260l/TbFvlTS9ZKG5pbvLOmxFP8tkm6SdFZuedXPptGc3M1a3xHAvsDWwDbAP+aWfRzYENgCmCBpZ+BKsr73NwJ+BUxWNgB6f/b3ReBnwGHApsALpHGFJa1LNpziPcBmwCeAqWk//wAcAnwhLXsV+GVaNh5Yn+wp9o2A44C3JX2MbCjH/SNiXeCzwMx0rEOA04CvAsOB/wYmpWXDyAZ3/0dgGNl4A7v3flpX8RlgDPC3wM+BHwFfAnYADpP0hbSe0vnYDNguvYczUhyDgduBq9M5nAQc2nWAGj+bhnFyN2t9F0fEgohYBpwNjMstex84PSLeiYi3ge8Av4qIaRGxMiKuIRvndtd+7u8IsocQH42Id4BTgd0kjQYOBF6OiPMj4i8RsTwipqX9HAv8KCI603ZnAF9LTT3vkSW3T6QYZ0TE67njf0rSRyNiYe7hx2OBn0XEnDT610+Bsan2/mXgqYi4NSLeI0vOL/fxHJ+Z3sN9wJvApIhYHBEvkn2R7AQQEXMjYko6P0uAC8i+wEjneA3gFxHxXkT8Gvhj7hi1fDYN4+Ru1vryPay+QFZr7LIkIv6Sm98CODn97H9N0mtktcv8Nn3Z32ZpHQAi4g3gFbKeX0eR1ZIr2QK4PRfDHLLRuzYB/p3s6fUbJb0k6V8krRkRb5LVnI8DFkq6S9Inc/u7KLe/ZWS16BEpxr++p8gGqci/x1osyk2/XWF+CICkjSXdKOlFZQPBX0f2a4EUx4ux6iAZ+Thq+WwaxsndrPXlO+HbnFU74eveXfYC4OyIGJr7WyciJvVzfy+RJSUAUtPJRsCL6VhbV4l5AVnzSj6OtSPixVSr/XFEbE/W9HIgcBRARNwbEXuTNQE9DVyW29+x3fb30Yj4A7Aw/54kqdt7bKSfkZ2jT0fEesCRfNC+vxAYkY7fJR9HLZ9Nw/hqeA/c3UDfubuBpjhe0p3AW2Ttzjf1sO5lZDXm35A1CawD7AE8GBHL+7G/G8hq2DeQ1b5/CkyLiPmSXgEukHQicAkwGNg+Nc1cCpwtaXxEvCBpOPDZiLhD0p7AUuAp4HWyZpqV6aLqZ8ja7d8G3iCr7ZP2d6akmRExW9L6wD4RcQtwF3CxpK+SdVB4PNm1g2ZYF/gz8JqkEcD/yy17KMV7gqRLgAPIBi56IC2v5bNpGNfczVrfDcB9wLz0d1a1FSNiOlnb7sVkFzHnAt+sY39TgX8iu2C5kKymfnhatpxsKM2vkLVxPwvsmTa9iCzR3idpOfAwHwzY83HgVrLEPgf4HVnzxkeAk8l+LSwja8v+bjrW7cC5ZF80rwOzgP3TsqXA14FzyJqMxgD/U+091enHwM5kCf4u4NddC9Koc18FjgFeI6vV30nWrl7rZ9MwTRsguy82X3+NOPmz6xUdhgfr6Ic2GqxjRkR0FBZAP0maD3w7In7TivuznkmaBlwaEVcN9LFdczczaxBJX5D0cUlrSBoPfJrsVtEB1+82d0mjgGvJfmK9D0yMiIsknUH202NJWvW01P1vy3NNvO+KrI2btaBtgZvJ7q55DvhaRCwsIpB6LqiuAE6OiEfTwwwzJE1Jyy6MiPPqD8+stUjaj6w9eRBweUSc08zjRcToVt6frSoiJgITi44D6miWSQ8YPJqml5NdGBnRqMDMWo2kQWRPWe4PbA+Mk7R9sVGZVdaQWyHT02o7AdPIHvs9QdJRwHSy2v2rPW2/4Zaf4sjrpva0illdThw2rPeVercLMDci5gFIuhE4mOyWPrOWUndylzSE7DapEyPi9XR/55lkN/qfCZwPfKvCdhOACQAjR46sNwyzgTCCVZ847OSD2/sqGjZsWIwePbqZMdmH2Pz581m6dGnFTtLqSu6S1iRL7NenfhSIiEW55ZeR3ee5mnzb1NixY4u/H9Osd5X+E632bzdfcdl8882ZPn16s+OyD6mOjup39/a7zT09YnsFMCciLsiVb5pb7VCyhw3MyqCTVR8nH8mqj+4DWcUlIjoiomP48OEDFpxZXj01992BbwBPSpqZyk4ju8g0lqxGM5+sNzezMngEGCNpS7K+VQ4H/q7YkMwq63dyj4jfU/lnalvc027WVxGxQtIJZD0aDiLrCnd2L5uZFcIdh5n1QXogzxUYa3nufsDMrISc3M3MSqglmmWWPT+L644cU3QYZmal4Zq7mVkJObmbmZWQk7uZWQk5uZuZlZCTu5lZCTm5m5mVkJO7mVkJObmbmZWQk7uZWQk5uZuZlZCTu5lZCTViDNX5wHJgJbAiIjokbQjcBIwmG7DjsN4GyTYzs8ZpVM19z4gYGxFdA/qdAkyNiDHA1DRvZmYDpFnNMgcD16Tpa4BDmnQcMzOroBHJPYD7JM1Io74DbBIRCwHS68YNOI6ZmdWoEf257x4RL0naGJgi6elaNkpfBBMANljb13XNzBqp7qwaES+l18XA7cAuwCJJmwKk18UVtpsYER0R0TFkcKVxts3MrL/qSu6SPiZp3a5pYB9gFjAZGJ9WGw/cUc9xzMysb+ptltkEuF1S175uiIh7JD0C3CzpGOBPwNfrPI6ZmfVBXck9IuYBO1YofwXYq559m5lZ//lKpplZCTm5m5mVkJO7mVkJObmbmZWQk7uZWQk5uZuZlZCTu1k3kkZJul/SHEmzJX0/lW8oaYqkZ9PrBkXHalaNk7vZ6lYAJ0fEdsCuwPGStsddWVsbcXI36yYiFkbEo2l6OTAHGIG7srY24uRu1gNJo4GdgGm4K2trI07uZlVIGgLcBpwYEa/3YbsJkqZLmr5kyZLmBWjWAyd3swokrUmW2K+PiF+n4l67soZVu7MePnz4wARs1o2Tu1k3yro5vQKYExEX5Ba5K2trG40YicmsbHYHvgE8KWlmKjsNOAd3ZW1twsndrJuI+D1QbXgwd2VtbaHfyV3StsBNuaKtgH8GhgLfAbquJJ0WEXf3O0IzM+uzfif3iHgGGAsgaRDwItkYqkcDF0bEeQ2J0MzM+qxRF1T3Ap6LiBcatD8zM6tDo5L74cCk3PwJkp6QdKX73zAzG3h1J3dJg4GDgFtS0SXA1mRNNguB86ts99cHPd54N+oNw8zMchpRc98feDQiFgFExKKIWBkR7wOXAbtU2ij/oMeQwdVuTDAzs/5oRHIfR65JpusJvuRQYFYDjmFmZn1Q133uktYB9gaOzRX/i6SxQADzuy0zM7MBUFdyj4i3gI26lX2jrojMzKxu7lvGzKyEnNzNzErIyd3MrISc3M3MSsjJ3cyshNzlr5nZAHv88cdXmd9xxx0bfgzX3M3MSsjJ3cyshJzczcxKyMndzKyEnNzNzErIyd3MrISc3M3MSsjJ3cyshPwQk7Ws6ScdsMp8xwV3FRSJWfupqeaeBrpeLGlWrmxDSVMkPZteN0jlkvQLSXPTINk7Nyt4MzOrrNZmmauB/bqVnQJMjYgxwNQ0D9mYqmPS3wSyAbPNzGwA1ZTcI+JBYFm34oOBa9L0NcAhufJrI/MwMLTbuKpmZtZk9VxQ3SQiFgKk141T+QhgQW69zlRmZmYDpBl3y6hCWay2kjRB0nRJ0994d7XFZmZWh3qS+6Ku5pb0ujiVdwKjcuuNBF7qvnFETIyIjojoGDK40veBWbEkDZL0mKQ70/yWkqalmwhukjS46BjNqqknuU8Gxqfp8cAdufKj0l0zuwJ/7mq+MWsz3wfm5ObPBS5MNxG8ChxTSFTW9nbcccdV/pqh1lshJwEPAdtK6pR0DHAOsLekZ4G90zzA3cA8YC5wGfDdhkdt1mSSRgIHAJeneQFfBG5Nq+RvIjBrOTU9xBQR46os2qvCugEcX09QZi3g58APgHXT/EbAaxGxIs37RgFrae5+wKwbSQcCiyNiRr64wqoV7wTI3yywZMmSpsRo1hsnd7PV7Q4cJGk+cCNZc8zPyZ7Z6Pq1W/FGAVj1ZoHhw4cPRLxmq3FyN+smIk6NiJERMRo4HPhtRBwB3A98La2Wv4nArOU4uZvV7ofASZLmkrXBX1FwPGZVuVdIsx5ExAPAA2l6HrBLkfGY1co1dzOzEnLN3VqW+2836z/X3M3MSsjJ3cyshJzczcxKyMndzKyEnNzNzErIyd3MrISc3M3MSsjJ3cyshHpN7pKulLRY0qxc2b9KelrSE5JulzQ0lY+W9Lakmenv0mYGb2ZmldVSc78a2K9b2RTgUxHxaeB/gVNzy56LiLHp77jGhGlmZn3Ra3KPiAeBZd3K7suNSPMwWd/WZmbWIhrR5v4t4L9y81umEeN/J+lz1TbKj1bzxrsVB7QxM7N+qqvjMEk/AlYA16eihcDmEfGKpL8B/kPSDhHxevdtI2IiMBFg8/XXcHY3M2ugftfcJY0HDgSOSINiExHvRMQraXoG8BywTSMCNTOz2vUruUvaj2xUmoMi4q1c+XBJg9L0VsAYYF4jAjUzs9r12iwjaRKwBzBMUidwOtndMWsBUyQBPJzujPk88BNJK4CVwHERsazijs3MrGl6Te4RMa5CccWxIyPiNuC2eoMyM7j33ntXmd93330LiuQDqTJHaom1FuYnVM3MSsjJ3cyshJzczcxKyANkm1nN3NbePlxzNzMrISd3M7MScnI3Myuhtm9z3/uzu60yP+UPDxUUiZlZ63DNvcGOvO5Zjrzu2aLDMLMPOSd3M7MScnI3q0DSUEm3puEk50jaTdKGkqZIeja9blB0nGbVOLmbVXYRcE9EfBLYEZgDnAJMjYgxwNQ0b9aS2v6Caqu57sgxRYdgdZK0HlkPp98EiIh3gXclHUzWQyrANcADZF1fm7Uc19zNVrcVsAS4Kg0ZebmkjwGbRMRCgPS6cZFBmvWk1+Qu6UpJiyXNypWdIelFSTPT35dzy06VNFfSM5KK76PUrO/WAHYGLomInYA36UMTTH584CVLljQrRrMe1dIsczVwMXBtt/ILI+K8fIGk7YHDgR2AzYDfSNomIlY2IFazgdIJdEbEtDR/K1lyXyRp04hYKGlTYHGljfPjA3d0dPS7M5ZW6L/d2levNfeIeBCodTSlg4Eb01iqzwNzgV3qiM9swEXEy8ACSdumor2Ap4DJwPhUNh64o4DwzGpSzwXVEyQdBUwHTo6IV4ERwMO5dTpTmVm7+R5wvaTBZOMAH01WGbpZ0jHAn4CvFxifWY/6m9wvAc4EIr2eD3wLUIV1K/4slTQBmACwwdq+rmutJSJmAh0VFu010LGY9Ue/smpELIqIlRHxPnAZHzS9dAKjcquOBF6qso+JEdERER1DBlf6TjAzs/7qV3JPF5O6HAp03UkzGThc0lqStgTGAH+sL0QzM+urXptlJE0ie3BjmKRO4HRgD0ljyZpc5gPHAkTEbEk3k118WgEc7ztlzMwGXq/JPSLGVSi+oof1zwbOricoMzOrT9t3P+D+283MVufbVMzMSsjJ3cyshJzczcxKyMndzKyEnNzNzErIyd3MrISc3M3MSsjJ3cyshJzczcxKyMndzKyEnNzNzErIyd3MrISc3M3MSsjJ3cyshHpN7pKulLRY0qxc2U2SZqa/+ZJmpvLRkt7OLbu0mcGbmVlltfTnfjVwMXBtV0FE/G3XtKTzgT/n1n8uIsY2KkAzM+u7WkZielDS6ErLJAk4DPhiY8MyM7N61Nvm/jlgUUQ8myvbUtJjkn4n6XN17t/MzPqh3mH2xgGTcvMLgc0j4hVJfwP8h6QdIuL17htKmgBMANhgbV/XNTNrpH5nVUlrAF8Fbuoqi4h3IuKVND0DeA7YptL2ETExIjoiomPIYPU3DDMzq6CeKvOXgKcjorOrQNJwSYPS9FbAGGBefSGamVlf1XIr5CTgIWBbSZ2SjkmLDmfVJhmAzwNPSHocuBU4LiKWNTJgMzPrXS13y4yrUv7NCmW3AbfVH5aZmdXDVzLNzErIyd3MrISc3M3MSsjJ3cyshOp9iMnMejBjxoylkt4ElhYdSwXDcFx90YpxbVFtgZO7WRNFxHBJ0yOio+hYunNcfdOqcVXjZhkzsxJycjczKyEnd7Pmm1h0AFU4rr5p1bgqcnI3a7KIaMmk4Lj6plXjqsbJ3cyshJzczZpE0n6SnpE0V9IpBcYxStL9kuZImi3p+6l8Q0lTJD2bXjcoKL5BaYCfO9P8lpKmpbhukjS4gJiGSrpV0tPpvO3WKuerVk7uZk2Qur7+JbA/sD0wTtL2BYWzAjg5IrYDdgWOT7GcAkyNiDHA1DRfhO8Dc3Lz5wIXprheBY6puFVzXQTcExGfBHZM8bXK+aqJIqLoGBg7dmxMnTq16DCsxIYNGzZjIO9RlrQbcEZE7JvmTwWIiJ8NVAzVSLqDbND7i4E9ImKhpE2BByJi2wGOZSRwDXA2cBLwFWAJ8PGIWNH9PA5QTOsBjwNbRS5BSnqGgs9XX7jmbtYcI4AFufnOVFaoNNj9TsA0YJOIWAiQXjcuIKSfAz8A3k/zGwGvRcSKNF/EeduK7AvmqtRcdLmkj9Ea56tmtQzW0af2OmV+kdoZn5C0c7PfhFkLqjR2ZKE/kyUNIRtv4cRK4xoXEM+BwOI0JOdfiyusOtDnbQ1gZ+CSiNgJeJMWb4KppJaae1/b6/YnG15vDNkA2Jc0PGqz1tcJjMrNjwReKigWJK1Jltivj4hfp+JFqXmB9Lp4gMPaHThI0nzgRuCLZDX5oWmMZijmvHUCnRExLc3fSpbsiz5ffdJrco+IhRHxaJpeTnZhYQRwMFlbGen1kDR9MHBtZB4m+6A2bXjkZq3tEWBMuvNjMNmwlJOLCESSgCuAORFxQW7RZGB8mh4P3DGQcUXEqRExMiJGk52f30bEEcD9wNcKjOtlYIGkrvb0vYCnKPh89VWfOg7rqb1OUlf7U7W2xoX1BmvWLtLFwBOAe4FBwJURMbugcHYHvgE8KWlmKjsNOAe4OY2L/Cfg6wXF190PgRslnQU8RvbFNNC+B1yfvpjnAUeTVYZb8XxVVHNy795el1UGKq9aoWy1NjNJE8iabRg5cmStYZi1jYi4G7i7BeL4PZX/X0JWKy1cRDwAPJCm5wG7FBzPTKDS3VUtcb5qUdPdMn1sr6uprTEiJkZER0R0bLTRRv2N38zMKqjlbpm+ttdNBo5Kd83sCvy5q/nGzMwGRi3NMn1tr7sb+DIwF3iLrK3KzMwGUK/Jva/tdemJruPrjMvMzOrgJ1TNzErIyd3MrISc3M3MSsjJ3cyshFqiy19JS8g651ladCz9NIz2jR3aO/5aY98iIoY3OxizVtESyR1A0vSB7G+7kdo5dmjv+Ns5drNmcrOMmVkJObmbmZVQKyX3iUUHUId2jh3aO/52jt2saVqmzd3MzBqnlWruZmbWIIUnd0n7SXomjbnaFuMUSpov6UlJMyVNT2UVx5RtBZKulLRY0qxcWVuMgVsl9jMkvZjO/0xJX84tOzXF/oykfYuJ2qx4hSZ3SYOAX5KNu7o9MC6Nz9oO9oyIsbnb8KqNKdsKrgb261bWLmPgXs3qsQNcmM7/2DQoBunfzuHADmmbf0v/xsw+dIquue8CzI2IeRHxLtkguQcXHFN/VRtTtnAR8SCwrFtxW4yBWyX2ag4GboyIdyLiebJupwsd0cesKEUn92rjrba6AO6TNCMNFwjdxpQFNq66dWuoFm+7fCYnpGajK3NNYO0Su1nTFZ3caxpvtQXtHhE7kzVhHC/p80UH1EDt8JlcAmwNjCUbeP38VN4OsZsNiKKTe03jrbaaiHgpvS4Gbif76V9tTNlWVdcYuEWKiEURsTIi3gcu44Oml5aP3WygFJ3cHwHGSNpS0mCyi2GTC46pR5I+JmndrmlgH2AW1ceUbVVtOwZut2sAh5Kdf8hiP1zSWpK2JLso/MeBjs+sFdQyhmrTRMQKSScA9wKDgCsjYnaRMdVgE+D2bNxw1gBuiIh7JD1C5TFlCydpErAHMExSJ3A6bTIGbpXY95A0lqzJZT5wLEBEzJZ0M/AUsAI4PiJWFhG3WdH8hKqZWQkV3SxjZmZN4ORuZlZCTu5mZiXk5G5mVkJO7mZmJeTkbmZWQk7uZmYl5ORuZlZC/x9DCJVDTdgyMQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display images\n",
    "env.reset()\n",
    "_, _, _, _ = env.step(0)\n",
    "# get a frame after 20 steps\n",
    "for _ in range(20):\n",
    "    frame, _, _, _ = env.step(1)\n",
    "\n",
    "# original image\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(frame)\n",
    "plt.title('original image')\n",
    "\n",
    "# preprocessed image\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('preprocessed image')\n",
    "# 80 x 80 black and white image\n",
    "plt.imshow(pong_utils.preprocess_single(frame), cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the policy\n",
    "\n",
    "# the output is the probability of moving right\n",
    "# where P(left) = 1-P(right)\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Policy(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Policy, self).__init__()\n",
    "        # 80x80x2 to 38x38x4\n",
    "        # 2 channel from the stacked frame\n",
    "        # new_size = (size - kernel_size)/stride + 1, i.e. (80 - 6)/2 + 1 = 38\n",
    "      \n",
    "        self.conv1 = nn.Conv2d(2, 4, kernel_size=6, stride=2, bias=False)\n",
    "        # 38x38x4 to 9x9x32\n",
    "        # new_size = (size - kernel_size)/stride + 1, i.e. (38 - 6)/4 + 1 = 9\n",
    "        self.conv2 = nn.Conv2d(4, 16, kernel_size=6, stride=4)\n",
    "        self.size=9*9*16\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.size, 512)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "\n",
    "        x = x.view(-1,self.size)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return self.sig(x)\n",
    "\n",
    "policy = pong_utils.Policy().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize model\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(policy.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<matplotlib.animation.FuncAnimation object at 0x7fa2aab67bd0>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-15acaf203dde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# add preprocessing stage and visualize the game\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpong_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfanim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Deep_Reinforcement_Learning/PONG_with_REINFORCE/pong_utils.py\u001b[0m in \u001b[0;36mplay\u001b[0;34m(env, policy, time, preprocess, nrand)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0manimate_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manim_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Deep_Reinforcement_Learning/PONG_with_REINFORCE/pong_utils.py\u001b[0m in \u001b[0;36manimate_frames\u001b[0;34m(frames)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfanim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisplay_animation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfanim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'once'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# play a game and display the animation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/JSAnimation/IPython_display.py\u001b[0m in \u001b[0;36mdisplay_animation\u001b[0;34m(anim, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;34m\"\"\"Display the animation with an IPython HTML object\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manim_to_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/JSAnimation/IPython_display.py\u001b[0m in \u001b[0;36manim_to_html\u001b[0;34m(anim, fps, embed_frames, default_mode)\u001b[0m\n\u001b[1;32m     74\u001b[0m             anim.save(f.name,  writer=HTMLWriter(fps=fps,\n\u001b[1;32m     75\u001b[0m                                                  \u001b[0membed_frames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membed_frames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                                                  default_mode=default_mode))\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filename, writer, fps, dpi, codec, bitrate, extra_args, metadata, extra_anim, savefig_kwargs, progress_callback)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                             \u001b[0mprogress_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                             \u001b[0mframe_number\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrab_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msavefig_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m         \u001b[0;31m# Reconnect signal for first draw if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36msaving\u001b[0;34m(self, fig, outfile, dpi, *args, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36mfinish\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;31m# are available to be assembled.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m         \u001b[0mMovieWriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Will call clean-up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36mfinish\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;34m'''Finish any processing for writing the movie.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrab_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msavefig_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36mcleanup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         \u001b[0mMovieWriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;31m# Delete temporary files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/animation.py\u001b[0m in \u001b[0;36mcleanup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_frame_sink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;31m# Use the encoding/errors that universal_newlines would use.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextIOWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m         \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextIOWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "# add preprocessing stage and visualize the game\n",
    "pong_utils.play(env, policy, time=2000, preprocess=None, nrand=5) \n",
    "print (fanim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect multiple samples from parrallelized environments\n",
    "from parallelEnv import parallelEnv \n",
    "envs = parallelEnv('PongDeterministic-v4', n=4, seed=12345)\n",
    "prob, state, action, reward = pong_utils.collect_trajectories(envs, policy, tmax=100)\n",
    "\n",
    "print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining surrogate fuction for training\n",
    "\n",
    "LSUR = pong_utils.surrogate(policy, prob, state, action, reward)\n",
    "print(LSUR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the agent\n",
    "\n",
    "from parallelEnv import parallelEnv\n",
    "import numpy as np\n",
    "\n",
    "episode = 1000\n",
    "! pip install progressbar\n",
    "import progressbar as pb\n",
    "widget = ['training loop: ', pb.Percentage(), ' ', \n",
    "          pb.Bar(), ' ', pb.ETA() ]\n",
    "timer = pb.ProgressBar(widgets=widget, maxval=episode).start()\n",
    "\n",
    "# initialize environment\n",
    "envs = parallelEnv('PongDeterministic-v4', n=8, seed=1234)\n",
    "\n",
    "discount_rate = .99\n",
    "beta = .01\n",
    "tmax = 320\n",
    "\n",
    "# keep track of progress\n",
    "mean_rewards = []\n",
    "\n",
    "for e in range(episode):\n",
    "\n",
    "    # collect trajectories\n",
    "    old_probs, states, actions, rewards = \\\n",
    "        pong_utils.collect_trajectories(envs, policy, tmax=tmax)\n",
    "        \n",
    "    total_rewards = np.sum(rewards, axis=0)\n",
    "\n",
    "    \n",
    "    L = -pong_utils.surrogate(policy, old_probs, states, actions, rewards, beta=beta)\n",
    "    optimizer.zero_grad()\n",
    "    L.backward()\n",
    "    optimizer.step()\n",
    "    del L\n",
    "        \n",
    "    # the regulation term also reduces\n",
    "    # this reduces exploration in later runs\n",
    "    beta*=.995\n",
    "    \n",
    "    # get the average reward of the parallel environments\n",
    "    mean_rewards.append(np.mean(total_rewards))\n",
    "    \n",
    "    # display some progress every 20 iterations\n",
    "    if (e+1)%20 ==0 :\n",
    "        print(\"Episode: {0:d}, score: {1:f}\".format(e+1,np.mean(total_rewards)))\n",
    "        print(total_rewards)\n",
    "        \n",
    "    # update progress widget bar\n",
    "    timer.update(e+1)\n",
    "    \n",
    "timer.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize game after training\n",
    "pong_utils.play(env, policy, time=2000) \n",
    "plt.plot(mean_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save policy\n",
    "torch.save(policy, 'REINFORCE.policy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and test policy\n",
    "policy = torch.load('REINFORCE.policy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
